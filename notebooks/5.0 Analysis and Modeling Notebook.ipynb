{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: right\"> Tommy Evans-Barton </div>\n",
    "<div style=\"text-align: right\"> WR Year 2 Jumps </div>\n",
    "\n",
    "# Analysis and Modeling Notebook\n",
    "\n",
    "The purpose of this notebook is to develop the model used to predict second year production for receivers based on their statistics in their first year. This notebook will also serve as a preliminary 'final notebook' before the final presentation of this project's findings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import Binarizer\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import r2_score\n",
    "import scipy.stats\n",
    "from scipy.optimize import minimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOP_PATH = os.environ['PWD']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading in Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rnd</th>\n",
       "      <th>Pick</th>\n",
       "      <th>Team</th>\n",
       "      <th>Player</th>\n",
       "      <th>First Year</th>\n",
       "      <th>Age Draft</th>\n",
       "      <th>G</th>\n",
       "      <th>GS</th>\n",
       "      <th>Tgt</th>\n",
       "      <th>WR Tgt Share</th>\n",
       "      <th>...</th>\n",
       "      <th>Projected Rec Share</th>\n",
       "      <th>Projected Rec</th>\n",
       "      <th>Projected Yds Share</th>\n",
       "      <th>Projected Yds</th>\n",
       "      <th>Projected TD Share</th>\n",
       "      <th>Projected TD</th>\n",
       "      <th>Rec Pts First Season</th>\n",
       "      <th>Rec Pts/G First Season</th>\n",
       "      <th>Rec Pts Second Season</th>\n",
       "      <th>Rec Pts/G Second Season</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>CLE</td>\n",
       "      <td>B.Edwards</td>\n",
       "      <td>2005</td>\n",
       "      <td>22</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>0.226923</td>\n",
       "      <td>...</td>\n",
       "      <td>0.425007</td>\n",
       "      <td>61.201005</td>\n",
       "      <td>0.498598</td>\n",
       "      <td>981.739542</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>2.0</td>\n",
       "      <td>69.2</td>\n",
       "      <td>6.920000</td>\n",
       "      <td>124.4</td>\n",
       "      <td>7.775000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>MIN</td>\n",
       "      <td>T.Williamson</td>\n",
       "      <td>2005</td>\n",
       "      <td>22</td>\n",
       "      <td>14.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>0.180556</td>\n",
       "      <td>...</td>\n",
       "      <td>0.484076</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>0.483380</td>\n",
       "      <td>1047.000000</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>4.0</td>\n",
       "      <td>49.2</td>\n",
       "      <td>3.514286</td>\n",
       "      <td>45.5</td>\n",
       "      <td>3.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>DET</td>\n",
       "      <td>M.Williams</td>\n",
       "      <td>2005</td>\n",
       "      <td>21</td>\n",
       "      <td>14.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>0.256757</td>\n",
       "      <td>...</td>\n",
       "      <td>0.381579</td>\n",
       "      <td>43.500000</td>\n",
       "      <td>0.257708</td>\n",
       "      <td>374.707921</td>\n",
       "      <td>-0.444444</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>2.928571</td>\n",
       "      <td>15.9</td>\n",
       "      <td>1.987500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>JAX</td>\n",
       "      <td>M.Jones</td>\n",
       "      <td>2005</td>\n",
       "      <td>22</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>0.206587</td>\n",
       "      <td>...</td>\n",
       "      <td>0.582418</td>\n",
       "      <td>106.000000</td>\n",
       "      <td>0.563735</td>\n",
       "      <td>1455.000000</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>11.0</td>\n",
       "      <td>73.2</td>\n",
       "      <td>4.575000</td>\n",
       "      <td>88.3</td>\n",
       "      <td>6.307143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>BAL</td>\n",
       "      <td>M.Clayton</td>\n",
       "      <td>2005</td>\n",
       "      <td>23</td>\n",
       "      <td>14.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>0.388393</td>\n",
       "      <td>...</td>\n",
       "      <td>0.338462</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>0.305052</td>\n",
       "      <td>471.000000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>59.1</td>\n",
       "      <td>4.221429</td>\n",
       "      <td>123.9</td>\n",
       "      <td>7.743750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>126</td>\n",
       "      <td>2</td>\n",
       "      <td>57</td>\n",
       "      <td>PHI</td>\n",
       "      <td>J.Arcega-Whiteside</td>\n",
       "      <td>2019</td>\n",
       "      <td>22</td>\n",
       "      <td>16.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.126437</td>\n",
       "      <td>...</td>\n",
       "      <td>0.485149</td>\n",
       "      <td>49.000000</td>\n",
       "      <td>0.450466</td>\n",
       "      <td>532.000000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>22.9</td>\n",
       "      <td>1.431250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>127</td>\n",
       "      <td>2</td>\n",
       "      <td>64</td>\n",
       "      <td>SEA</td>\n",
       "      <td>D.Metcalf</td>\n",
       "      <td>2019</td>\n",
       "      <td>21</td>\n",
       "      <td>16.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.375940</td>\n",
       "      <td>...</td>\n",
       "      <td>0.424419</td>\n",
       "      <td>73.000000</td>\n",
       "      <td>0.457451</td>\n",
       "      <td>1145.000000</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>8.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>8.250000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>128</td>\n",
       "      <td>3</td>\n",
       "      <td>66</td>\n",
       "      <td>PIT</td>\n",
       "      <td>D.Johnson</td>\n",
       "      <td>2019</td>\n",
       "      <td>23</td>\n",
       "      <td>16.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>0.380165</td>\n",
       "      <td>...</td>\n",
       "      <td>0.406897</td>\n",
       "      <td>59.000000</td>\n",
       "      <td>0.345704</td>\n",
       "      <td>680.000000</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>5.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>6.125000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>129</td>\n",
       "      <td>3</td>\n",
       "      <td>76</td>\n",
       "      <td>WAS</td>\n",
       "      <td>T.McLaurin</td>\n",
       "      <td>2019</td>\n",
       "      <td>23</td>\n",
       "      <td>14.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>0.505435</td>\n",
       "      <td>...</td>\n",
       "      <td>0.508772</td>\n",
       "      <td>58.000000</td>\n",
       "      <td>0.620108</td>\n",
       "      <td>919.000000</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>7.0</td>\n",
       "      <td>133.9</td>\n",
       "      <td>9.564286</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>3</td>\n",
       "      <td>93</td>\n",
       "      <td>BAL</td>\n",
       "      <td>M.Boykin</td>\n",
       "      <td>2019</td>\n",
       "      <td>22</td>\n",
       "      <td>16.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.122905</td>\n",
       "      <td>...</td>\n",
       "      <td>0.298246</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>0.331918</td>\n",
       "      <td>469.000000</td>\n",
       "      <td>0.294118</td>\n",
       "      <td>5.0</td>\n",
       "      <td>37.8</td>\n",
       "      <td>2.362500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>131 rows × 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Rnd  Pick Team              Player  First Year  Age Draft     G    GS  \\\n",
       "0      1     3  CLE           B.Edwards        2005         22  10.0   7.0   \n",
       "1      1     7  MIN        T.Williamson        2005         22  14.0   3.0   \n",
       "2      1    10  DET          M.Williams        2005         21  14.0   4.0   \n",
       "3      1    21  JAX             M.Jones        2005         22  16.0   1.0   \n",
       "4      1    22  BAL           M.Clayton        2005         23  14.0  10.0   \n",
       "..   ...   ...  ...                 ...         ...        ...   ...   ...   \n",
       "126    2    57  PHI  J.Arcega-Whiteside        2019         22  16.0   5.0   \n",
       "127    2    64  SEA           D.Metcalf        2019         21  16.0  15.0   \n",
       "128    3    66  PIT           D.Johnson        2019         23  16.0  12.0   \n",
       "129    3    76  WAS          T.McLaurin        2019         23  14.0  14.0   \n",
       "130    3    93  BAL            M.Boykin        2019         22  16.0  11.0   \n",
       "\n",
       "       Tgt  WR Tgt Share  ...  Projected Rec Share  Projected Rec  \\\n",
       "0     59.0      0.226923  ...             0.425007      61.201005   \n",
       "1     52.0      0.180556  ...             0.484076      76.000000   \n",
       "2     57.0      0.256757  ...             0.381579      43.500000   \n",
       "3     69.0      0.206587  ...             0.582418     106.000000   \n",
       "4     87.0      0.388393  ...             0.338462      44.000000   \n",
       "..     ...           ...  ...                  ...            ...   \n",
       "126   22.0      0.126437  ...             0.485149      49.000000   \n",
       "127  100.0      0.375940  ...             0.424419      73.000000   \n",
       "128   92.0      0.380165  ...             0.406897      59.000000   \n",
       "129   93.0      0.505435  ...             0.508772      58.000000   \n",
       "130   22.0      0.122905  ...             0.298246      34.000000   \n",
       "\n",
       "     Projected Yds Share  Projected Yds  Projected TD Share  Projected TD  \\\n",
       "0               0.498598     981.739542            0.222222           2.0   \n",
       "1               0.483380    1047.000000            0.307692           4.0   \n",
       "2               0.257708     374.707921           -0.444444          -4.0   \n",
       "3               0.563735    1455.000000            0.611111          11.0   \n",
       "4               0.305052     471.000000            0.400000           2.0   \n",
       "..                   ...            ...                 ...           ...   \n",
       "126             0.450466     532.000000            0.400000           4.0   \n",
       "127             0.457451    1145.000000            0.444444           8.0   \n",
       "128             0.345704     680.000000            0.454545           5.0   \n",
       "129             0.620108     919.000000            0.875000           7.0   \n",
       "130             0.331918     469.000000            0.294118           5.0   \n",
       "\n",
       "     Rec Pts First Season  Rec Pts/G First Season  Rec Pts Second Season  \\\n",
       "0                    69.2                6.920000                  124.4   \n",
       "1                    49.2                3.514286                   45.5   \n",
       "2                    41.0                2.928571                   15.9   \n",
       "3                    73.2                4.575000                   88.3   \n",
       "4                    59.1                4.221429                  123.9   \n",
       "..                    ...                     ...                    ...   \n",
       "126                  22.9                1.431250                    NaN   \n",
       "127                 132.0                8.250000                    NaN   \n",
       "128                  98.0                6.125000                    NaN   \n",
       "129                 133.9                9.564286                    NaN   \n",
       "130                  37.8                2.362500                    NaN   \n",
       "\n",
       "     Rec Pts/G Second Season  \n",
       "0                   7.775000  \n",
       "1                   3.250000  \n",
       "2                   1.987500  \n",
       "3                   6.307143  \n",
       "4                   7.743750  \n",
       "..                       ...  \n",
       "126                      NaN  \n",
       "127                      NaN  \n",
       "128                      NaN  \n",
       "129                      NaN  \n",
       "130                      NaN  \n",
       "\n",
       "[131 rows x 42 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(TOP_PATH + '/data/final/FINAL_DATA.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting the Data into Modeling and Prediction Data\n",
    "Some of the data (the players who have not yet had second seasons) don't have a target for us to model onto, since this is a 'supervised learning' problem. These players will be moved into a different dataframe for future use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model = df[df['First Year'] < 2019].reset_index(drop = True)\n",
    "df_prediction = df[df['First Year'] == 2019].reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rnd</th>\n",
       "      <th>Pick</th>\n",
       "      <th>Team</th>\n",
       "      <th>Player</th>\n",
       "      <th>First Year</th>\n",
       "      <th>Age Draft</th>\n",
       "      <th>G</th>\n",
       "      <th>GS</th>\n",
       "      <th>Tgt</th>\n",
       "      <th>WR Tgt Share</th>\n",
       "      <th>...</th>\n",
       "      <th>Projected Rec Share</th>\n",
       "      <th>Projected Rec</th>\n",
       "      <th>Projected Yds Share</th>\n",
       "      <th>Projected Yds</th>\n",
       "      <th>Projected TD Share</th>\n",
       "      <th>Projected TD</th>\n",
       "      <th>Rec Pts First Season</th>\n",
       "      <th>Rec Pts/G First Season</th>\n",
       "      <th>Rec Pts Second Season</th>\n",
       "      <th>Rec Pts/G Second Season</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>CLE</td>\n",
       "      <td>B.Edwards</td>\n",
       "      <td>2005</td>\n",
       "      <td>22</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>0.226923</td>\n",
       "      <td>...</td>\n",
       "      <td>0.425007</td>\n",
       "      <td>61.201005</td>\n",
       "      <td>0.498598</td>\n",
       "      <td>981.739542</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>69.2</td>\n",
       "      <td>6.920000</td>\n",
       "      <td>124.4</td>\n",
       "      <td>7.775000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>MIN</td>\n",
       "      <td>T.Williamson</td>\n",
       "      <td>2005</td>\n",
       "      <td>22</td>\n",
       "      <td>14.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>0.180556</td>\n",
       "      <td>...</td>\n",
       "      <td>0.484076</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>0.483380</td>\n",
       "      <td>1047.000000</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>49.2</td>\n",
       "      <td>3.514286</td>\n",
       "      <td>45.5</td>\n",
       "      <td>3.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>DET</td>\n",
       "      <td>M.Williams</td>\n",
       "      <td>2005</td>\n",
       "      <td>21</td>\n",
       "      <td>14.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>0.256757</td>\n",
       "      <td>...</td>\n",
       "      <td>0.381579</td>\n",
       "      <td>43.500000</td>\n",
       "      <td>0.257708</td>\n",
       "      <td>374.707921</td>\n",
       "      <td>-0.444444</td>\n",
       "      <td>-4.000000</td>\n",
       "      <td>41.0</td>\n",
       "      <td>2.928571</td>\n",
       "      <td>15.9</td>\n",
       "      <td>1.987500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>JAX</td>\n",
       "      <td>M.Jones</td>\n",
       "      <td>2005</td>\n",
       "      <td>22</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>0.206587</td>\n",
       "      <td>...</td>\n",
       "      <td>0.582418</td>\n",
       "      <td>106.000000</td>\n",
       "      <td>0.563735</td>\n",
       "      <td>1455.000000</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>73.2</td>\n",
       "      <td>4.575000</td>\n",
       "      <td>88.3</td>\n",
       "      <td>6.307143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>BAL</td>\n",
       "      <td>M.Clayton</td>\n",
       "      <td>2005</td>\n",
       "      <td>23</td>\n",
       "      <td>14.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>0.388393</td>\n",
       "      <td>...</td>\n",
       "      <td>0.338462</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>0.305052</td>\n",
       "      <td>471.000000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>59.1</td>\n",
       "      <td>4.221429</td>\n",
       "      <td>123.9</td>\n",
       "      <td>7.743750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>116</td>\n",
       "      <td>2</td>\n",
       "      <td>51</td>\n",
       "      <td>CHI</td>\n",
       "      <td>A.Miller</td>\n",
       "      <td>2018</td>\n",
       "      <td>23</td>\n",
       "      <td>15.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.192171</td>\n",
       "      <td>...</td>\n",
       "      <td>0.544404</td>\n",
       "      <td>98.537037</td>\n",
       "      <td>0.495570</td>\n",
       "      <td>1036.732673</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>84.3</td>\n",
       "      <td>5.620000</td>\n",
       "      <td>77.6</td>\n",
       "      <td>4.850000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>117</td>\n",
       "      <td>2</td>\n",
       "      <td>60</td>\n",
       "      <td>PIT</td>\n",
       "      <td>J.Washington</td>\n",
       "      <td>2018</td>\n",
       "      <td>22</td>\n",
       "      <td>14.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0.094763</td>\n",
       "      <td>...</td>\n",
       "      <td>0.550607</td>\n",
       "      <td>136.000000</td>\n",
       "      <td>0.532306</td>\n",
       "      <td>1623.000000</td>\n",
       "      <td>0.695652</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>27.7</td>\n",
       "      <td>1.978571</td>\n",
       "      <td>91.5</td>\n",
       "      <td>6.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>118</td>\n",
       "      <td>2</td>\n",
       "      <td>61</td>\n",
       "      <td>JAX</td>\n",
       "      <td>D.Chark</td>\n",
       "      <td>2018</td>\n",
       "      <td>21</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.109589</td>\n",
       "      <td>...</td>\n",
       "      <td>0.208546</td>\n",
       "      <td>34.618557</td>\n",
       "      <td>0.291061</td>\n",
       "      <td>596.675743</td>\n",
       "      <td>0.148148</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>17.4</td>\n",
       "      <td>1.581818</td>\n",
       "      <td>148.8</td>\n",
       "      <td>9.920000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>119</td>\n",
       "      <td>3</td>\n",
       "      <td>81</td>\n",
       "      <td>DAL</td>\n",
       "      <td>M.Gallup</td>\n",
       "      <td>2018</td>\n",
       "      <td>22</td>\n",
       "      <td>16.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>0.311927</td>\n",
       "      <td>...</td>\n",
       "      <td>0.787760</td>\n",
       "      <td>107.923077</td>\n",
       "      <td>0.795709</td>\n",
       "      <td>1346.339575</td>\n",
       "      <td>0.677778</td>\n",
       "      <td>6.100000</td>\n",
       "      <td>62.7</td>\n",
       "      <td>3.918750</td>\n",
       "      <td>146.7</td>\n",
       "      <td>10.478571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>3</td>\n",
       "      <td>91</td>\n",
       "      <td>NOR</td>\n",
       "      <td>T.Smith</td>\n",
       "      <td>2018</td>\n",
       "      <td>22</td>\n",
       "      <td>15.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.159420</td>\n",
       "      <td>...</td>\n",
       "      <td>0.256039</td>\n",
       "      <td>53.000000</td>\n",
       "      <td>0.320792</td>\n",
       "      <td>810.000000</td>\n",
       "      <td>0.409091</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>72.7</td>\n",
       "      <td>4.846667</td>\n",
       "      <td>53.4</td>\n",
       "      <td>4.854545</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>121 rows × 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Rnd  Pick Team        Player  First Year  Age Draft     G    GS   Tgt  \\\n",
       "0      1     3  CLE     B.Edwards        2005         22  10.0   7.0  59.0   \n",
       "1      1     7  MIN  T.Williamson        2005         22  14.0   3.0  52.0   \n",
       "2      1    10  DET    M.Williams        2005         21  14.0   4.0  57.0   \n",
       "3      1    21  JAX       M.Jones        2005         22  16.0   1.0  69.0   \n",
       "4      1    22  BAL     M.Clayton        2005         23  14.0  10.0  87.0   \n",
       "..   ...   ...  ...           ...         ...        ...   ...   ...   ...   \n",
       "116    2    51  CHI      A.Miller        2018         23  15.0   4.0  54.0   \n",
       "117    2    60  PIT  J.Washington        2018         22  14.0   6.0  38.0   \n",
       "118    2    61  JAX       D.Chark        2018         21  11.0   0.0  32.0   \n",
       "119    3    81  DAL      M.Gallup        2018         22  16.0   8.0  68.0   \n",
       "120    3    91  NOR       T.Smith        2018         22  15.0   7.0  44.0   \n",
       "\n",
       "     WR Tgt Share  ...  Projected Rec Share  Projected Rec  \\\n",
       "0        0.226923  ...             0.425007      61.201005   \n",
       "1        0.180556  ...             0.484076      76.000000   \n",
       "2        0.256757  ...             0.381579      43.500000   \n",
       "3        0.206587  ...             0.582418     106.000000   \n",
       "4        0.388393  ...             0.338462      44.000000   \n",
       "..            ...  ...                  ...            ...   \n",
       "116      0.192171  ...             0.544404      98.537037   \n",
       "117      0.094763  ...             0.550607     136.000000   \n",
       "118      0.109589  ...             0.208546      34.618557   \n",
       "119      0.311927  ...             0.787760     107.923077   \n",
       "120      0.159420  ...             0.256039      53.000000   \n",
       "\n",
       "     Projected Yds Share  Projected Yds  Projected TD Share  Projected TD  \\\n",
       "0               0.498598     981.739542            0.222222      2.000000   \n",
       "1               0.483380    1047.000000            0.307692      4.000000   \n",
       "2               0.257708     374.707921           -0.444444     -4.000000   \n",
       "3               0.563735    1455.000000            0.611111     11.000000   \n",
       "4               0.305052     471.000000            0.400000      2.000000   \n",
       "..                   ...            ...                 ...           ...   \n",
       "116             0.495570    1036.732673            0.533333      8.000000   \n",
       "117             0.532306    1623.000000            0.695652     16.000000   \n",
       "118             0.291061     596.675743            0.148148      1.333333   \n",
       "119             0.795709    1346.339575            0.677778      6.100000   \n",
       "120             0.320792     810.000000            0.409091      9.000000   \n",
       "\n",
       "     Rec Pts First Season  Rec Pts/G First Season  Rec Pts Second Season  \\\n",
       "0                    69.2                6.920000                  124.4   \n",
       "1                    49.2                3.514286                   45.5   \n",
       "2                    41.0                2.928571                   15.9   \n",
       "3                    73.2                4.575000                   88.3   \n",
       "4                    59.1                4.221429                  123.9   \n",
       "..                    ...                     ...                    ...   \n",
       "116                  84.3                5.620000                   77.6   \n",
       "117                  27.7                1.978571                   91.5   \n",
       "118                  17.4                1.581818                  148.8   \n",
       "119                  62.7                3.918750                  146.7   \n",
       "120                  72.7                4.846667                   53.4   \n",
       "\n",
       "     Rec Pts/G Second Season  \n",
       "0                   7.775000  \n",
       "1                   3.250000  \n",
       "2                   1.987500  \n",
       "3                   6.307143  \n",
       "4                   7.743750  \n",
       "..                       ...  \n",
       "116                 4.850000  \n",
       "117                 6.100000  \n",
       "118                 9.920000  \n",
       "119                10.478571  \n",
       "120                 4.854545  \n",
       "\n",
       "[121 rows x 42 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train-Valid-Test Splitting\n",
    "Next I'm going to split the modeling data into pieces in order to have part of it to train the model on, and part of it to test on. In terms of the training, I chose to use the k-folds cross validation strategy, due to the low amount of samples, with k = 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_full_train, X_test, y_full_train, y_test = train_test_split(df_model.drop(\n",
    "    ['Rec Pts Second Season', 'Rec Pts/G Second Season'], axis = 1), \n",
    "    df_model['Rec Pts/G Second Season'], test_size = 0.2, random_state = 3)\n",
    "X_full_train = X_full_train.reset_index(drop = True)\n",
    "X_test = X_test.reset_index(drop = True)\n",
    "y_full_train = y_full_train.reset_index(drop = True)\n",
    "y_test = y_test.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(12)\n",
    "indices = np.random.choice(len(X_full_train.index), len(X_full_train.index), replace = False)\n",
    "splitter = len(indices)//5\n",
    "fold_1_x = X_full_train.iloc[indices[: splitter]]\n",
    "fold_1_y = y_full_train.iloc[indices[: splitter]]\n",
    "fold_2_x = X_full_train.iloc[indices[splitter : 2 * splitter]]\n",
    "fold_2_y = y_full_train.iloc[indices[splitter : 2 * splitter]]\n",
    "fold_3_x = X_full_train.iloc[indices[2 * splitter : 3 * splitter]]\n",
    "fold_3_y = y_full_train.iloc[indices[2 * splitter : 3 * splitter]]\n",
    "fold_4_x = X_full_train.iloc[indices[3 * splitter : 4 * splitter]]\n",
    "fold_4_y = y_full_train.iloc[indices[3 * splitter : 4 * splitter]]\n",
    "fold_5_x = X_full_train.iloc[indices[4 * splitter :]]\n",
    "fold_5_y = y_full_train.iloc[indices[4 * splitter :]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a Baseline Model\n",
    "Its important to have some kind of baseline (or dummy) model to compare our model to. For the purposes of this project, the baseline will be predicting that the receiver has the same Rec Pts/G in their second season as their first. \n",
    "\n",
    "Based on this, it seems that the average $R^2$ coefficient for the baseline is around *0.216*, giving us the number to beat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold_1_y_baseline = fold_1_x['Rec Pts/G First Season']\n",
    "fold_2_y_baseline = fold_2_x['Rec Pts/G First Season']\n",
    "fold_3_y_baseline = fold_3_x['Rec Pts/G First Season']\n",
    "fold_4_y_baseline = fold_4_x['Rec Pts/G First Season']\n",
    "fold_5_y_baseline = fold_5_x['Rec Pts/G First Season']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1797271534597592\n",
      "0.44815436291566646\n",
      "-0.08994188232781553\n",
      "0.1877306170680606\n",
      "0.35799257258639594\n",
      "--------------------\n",
      "0.21673256474041333\n"
     ]
    }
   ],
   "source": [
    "print(r2_score(fold_5_y, fold_5_y_baseline))\n",
    "print(r2_score(fold_4_y, fold_4_y_baseline))\n",
    "print(r2_score(fold_3_y, fold_3_y_baseline))\n",
    "print(r2_score(fold_2_y, fold_2_y_baseline))\n",
    "print(r2_score(fold_1_y, fold_1_y_baseline))\n",
    "print('--------------------')\n",
    "print(np.mean([r2_score(fold_5_y, fold_5_y_baseline), r2_score(fold_4_y, fold_4_y_baseline), \n",
    "              r2_score(fold_3_y, fold_3_y_baseline), r2_score(fold_2_y, fold_2_y_baseline), \n",
    "              r2_score(fold_1_y, fold_1_y_baseline)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining and Sorting the Different Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 625,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_feat = ['Age Draft']\n",
    "thresh_feat = ['GS']\n",
    "reg_num_feat = ['Pick', 'First Year', 'G', 'GS',\n",
    "        'Tgt', 'Catch Rate', 'Y/R', 'TD', 'WR TD Share', 'Lng', 'Y/Tgt', 'Y/G', \n",
    "        'Projected Tgt Share', 'Projected Tgt', 'Projected Rec Share', 'Projected Rec', 'Projected Yds Share',\n",
    "        'Projected Yds', 'Projected TD Share', 'Projected TD']\n",
    "sqrt_num_feat = ['WR Tgt Share', 'Rec', 'WR Rec Share', 'Yds', 'WR Yds Share', '1D', \n",
    "                 'R/G', 'EYds', 'Rec Pts First Season', 'Rec Pts/G First Season']\n",
    "adv_num_feat = ['DYAR', 'YAR', 'DVOA', 'VOA', 'DPI Pens', 'DPI Yds']\n",
    "num_feat = reg_num_feat + sqrt_num_feat + adv_num_feat\n",
    "\n",
    "\n",
    "small_selection = ['Y/G', 'Lng', 'Projected Yds']\n",
    "small_sqrt = ['Yds', '1D', 'EYds', 'Rec Pts/G First Season', 'WR Tgt Share', 'WR Rec Share']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the Different Transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 626,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_transformer = Pipeline(steps=[\n",
    "    ('onehot', OneHotEncoder(categories = 'auto'))     # categorical columns become input to OneHot\n",
    "])\n",
    "\n",
    "thresh_transformer = Pipeline(steps=[\n",
    "    ('binarizer', Binarizer(threshold = 8))\n",
    "])\n",
    "\n",
    "sqrt_transformer = Pipeline(steps = [\n",
    "    ('sqrt', FunctionTransformer(lambda x : x**.5))\n",
    "])\n",
    "\n",
    "num_transformer = Pipeline(steps=[\n",
    "    ('none', FunctionTransformer(lambda x : x))\n",
    "])\n",
    "\n",
    "preproc1 = ColumnTransformer(transformers=[('sqrt', sqrt_transformer, small_sqrt), \n",
    "                                           ('none', num_transformer, small_selection), \n",
    "                                           ('cat', cat_transformer, cat_feat), \n",
    "                                           ('thresh', thresh_transformer, thresh_feat)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the Different Pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 627,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl_1 = Pipeline(steps=[('preprocessor', preproc1), ('regressor', Ridge(alpha = .7, normalize = True))]) #k5 as valid\n",
    "pl_2 = Pipeline(steps=[('preprocessor', preproc1), ('regressor', Ridge(alpha = .7, normalize = True))]) #k4 as valid\n",
    "pl_3 = Pipeline(steps=[('preprocessor', preproc1), ('regressor', Ridge(alpha = .7, normalize = True))]) #k3 as valid\n",
    "pl_4 = Pipeline(steps=[('preprocessor', preproc1), ('regressor', Ridge(alpha = .7, normalize = True))]) #k2 as valid\n",
    "pl_5 = Pipeline(steps=[('preprocessor', preproc1), ('regressor', Ridge(alpha = .7, normalize = True))]) #k1 as valid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit the Different Pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 628,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/_function_transformer.py:97: FutureWarning: The default validate=True will be replaced by validate=False in 0.22.\n",
      "  \"validate=False in 0.22.\", FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/_function_transformer.py:97: FutureWarning: The default validate=True will be replaced by validate=False in 0.22.\n",
      "  \"validate=False in 0.22.\", FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/_function_transformer.py:97: FutureWarning: The default validate=True will be replaced by validate=False in 0.22.\n",
      "  \"validate=False in 0.22.\", FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/_function_transformer.py:97: FutureWarning: The default validate=True will be replaced by validate=False in 0.22.\n",
      "  \"validate=False in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('preprocessor',\n",
       "                 ColumnTransformer(n_jobs=None, remainder='drop',\n",
       "                                   sparse_threshold=0.3,\n",
       "                                   transformer_weights=None,\n",
       "                                   transformers=[('sqrt',\n",
       "                                                  Pipeline(memory=None,\n",
       "                                                           steps=[('sqrt',\n",
       "                                                                   FunctionTransformer(accept_sparse=False,\n",
       "                                                                                       check_inverse=True,\n",
       "                                                                                       func=<function <lambda> at 0x7f929026ca70>,\n",
       "                                                                                       inv_kw_args=None,\n",
       "                                                                                       inverse_func=None,\n",
       "                                                                                       kw_args=None,\n",
       "                                                                                       pass_y='...\n",
       "                                                                                 handle_unknown='error',\n",
       "                                                                                 n_values=None,\n",
       "                                                                                 sparse=True))],\n",
       "                                                           verbose=False),\n",
       "                                                  ['Age Draft']),\n",
       "                                                 ('thresh',\n",
       "                                                  Pipeline(memory=None,\n",
       "                                                           steps=[('binarizer',\n",
       "                                                                   Binarizer(copy=True,\n",
       "                                                                             threshold=8))],\n",
       "                                                           verbose=False),\n",
       "                                                  ['GS'])],\n",
       "                                   verbose=False)),\n",
       "                ('regressor',\n",
       "                 Ridge(alpha=0.7, copy_X=True, fit_intercept=True,\n",
       "                       max_iter=None, normalize=True, random_state=None,\n",
       "                       solver='auto', tol=0.001))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 628,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pl_1.fit(pd.concat([fold_1_x, fold_2_x, fold_3_x, fold_4_x])[small_selection + small_sqrt + cat_feat + thresh_feat],\n",
    "         pd.concat([fold_1_y, fold_2_y, fold_3_y, fold_4_y]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 629,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/_function_transformer.py:97: FutureWarning: The default validate=True will be replaced by validate=False in 0.22.\n",
      "  \"validate=False in 0.22.\", FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/_function_transformer.py:97: FutureWarning: The default validate=True will be replaced by validate=False in 0.22.\n",
      "  \"validate=False in 0.22.\", FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/_function_transformer.py:97: FutureWarning: The default validate=True will be replaced by validate=False in 0.22.\n",
      "  \"validate=False in 0.22.\", FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/_function_transformer.py:97: FutureWarning: The default validate=True will be replaced by validate=False in 0.22.\n",
      "  \"validate=False in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('preprocessor',\n",
       "                 ColumnTransformer(n_jobs=None, remainder='drop',\n",
       "                                   sparse_threshold=0.3,\n",
       "                                   transformer_weights=None,\n",
       "                                   transformers=[('sqrt',\n",
       "                                                  Pipeline(memory=None,\n",
       "                                                           steps=[('sqrt',\n",
       "                                                                   FunctionTransformer(accept_sparse=False,\n",
       "                                                                                       check_inverse=True,\n",
       "                                                                                       func=<function <lambda> at 0x7f929026ca70>,\n",
       "                                                                                       inv_kw_args=None,\n",
       "                                                                                       inverse_func=None,\n",
       "                                                                                       kw_args=None,\n",
       "                                                                                       pass_y='...\n",
       "                                                                                 handle_unknown='error',\n",
       "                                                                                 n_values=None,\n",
       "                                                                                 sparse=True))],\n",
       "                                                           verbose=False),\n",
       "                                                  ['Age Draft']),\n",
       "                                                 ('thresh',\n",
       "                                                  Pipeline(memory=None,\n",
       "                                                           steps=[('binarizer',\n",
       "                                                                   Binarizer(copy=True,\n",
       "                                                                             threshold=8))],\n",
       "                                                           verbose=False),\n",
       "                                                  ['GS'])],\n",
       "                                   verbose=False)),\n",
       "                ('regressor',\n",
       "                 Ridge(alpha=0.7, copy_X=True, fit_intercept=True,\n",
       "                       max_iter=None, normalize=True, random_state=None,\n",
       "                       solver='auto', tol=0.001))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 629,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pl_2.fit(pd.concat([fold_1_x, fold_2_x, fold_3_x, fold_5_x])[small_selection + small_sqrt + cat_feat + thresh_feat],\n",
    "         pd.concat([fold_1_y, fold_2_y, fold_3_y, fold_5_y]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 630,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/_function_transformer.py:97: FutureWarning: The default validate=True will be replaced by validate=False in 0.22.\n",
      "  \"validate=False in 0.22.\", FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/_function_transformer.py:97: FutureWarning: The default validate=True will be replaced by validate=False in 0.22.\n",
      "  \"validate=False in 0.22.\", FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/_function_transformer.py:97: FutureWarning: The default validate=True will be replaced by validate=False in 0.22.\n",
      "  \"validate=False in 0.22.\", FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/_function_transformer.py:97: FutureWarning: The default validate=True will be replaced by validate=False in 0.22.\n",
      "  \"validate=False in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('preprocessor',\n",
       "                 ColumnTransformer(n_jobs=None, remainder='drop',\n",
       "                                   sparse_threshold=0.3,\n",
       "                                   transformer_weights=None,\n",
       "                                   transformers=[('sqrt',\n",
       "                                                  Pipeline(memory=None,\n",
       "                                                           steps=[('sqrt',\n",
       "                                                                   FunctionTransformer(accept_sparse=False,\n",
       "                                                                                       check_inverse=True,\n",
       "                                                                                       func=<function <lambda> at 0x7f929026ca70>,\n",
       "                                                                                       inv_kw_args=None,\n",
       "                                                                                       inverse_func=None,\n",
       "                                                                                       kw_args=None,\n",
       "                                                                                       pass_y='...\n",
       "                                                                                 handle_unknown='error',\n",
       "                                                                                 n_values=None,\n",
       "                                                                                 sparse=True))],\n",
       "                                                           verbose=False),\n",
       "                                                  ['Age Draft']),\n",
       "                                                 ('thresh',\n",
       "                                                  Pipeline(memory=None,\n",
       "                                                           steps=[('binarizer',\n",
       "                                                                   Binarizer(copy=True,\n",
       "                                                                             threshold=8))],\n",
       "                                                           verbose=False),\n",
       "                                                  ['GS'])],\n",
       "                                   verbose=False)),\n",
       "                ('regressor',\n",
       "                 Ridge(alpha=0.7, copy_X=True, fit_intercept=True,\n",
       "                       max_iter=None, normalize=True, random_state=None,\n",
       "                       solver='auto', tol=0.001))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 630,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pl_3.fit(pd.concat([fold_1_x, fold_2_x, fold_4_x, fold_5_x])[small_selection + small_sqrt + cat_feat + thresh_feat],\n",
    "         pd.concat([fold_1_y, fold_2_y, fold_4_y, fold_5_y]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 631,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/_function_transformer.py:97: FutureWarning: The default validate=True will be replaced by validate=False in 0.22.\n",
      "  \"validate=False in 0.22.\", FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/_function_transformer.py:97: FutureWarning: The default validate=True will be replaced by validate=False in 0.22.\n",
      "  \"validate=False in 0.22.\", FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/_function_transformer.py:97: FutureWarning: The default validate=True will be replaced by validate=False in 0.22.\n",
      "  \"validate=False in 0.22.\", FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/_function_transformer.py:97: FutureWarning: The default validate=True will be replaced by validate=False in 0.22.\n",
      "  \"validate=False in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('preprocessor',\n",
       "                 ColumnTransformer(n_jobs=None, remainder='drop',\n",
       "                                   sparse_threshold=0.3,\n",
       "                                   transformer_weights=None,\n",
       "                                   transformers=[('sqrt',\n",
       "                                                  Pipeline(memory=None,\n",
       "                                                           steps=[('sqrt',\n",
       "                                                                   FunctionTransformer(accept_sparse=False,\n",
       "                                                                                       check_inverse=True,\n",
       "                                                                                       func=<function <lambda> at 0x7f929026ca70>,\n",
       "                                                                                       inv_kw_args=None,\n",
       "                                                                                       inverse_func=None,\n",
       "                                                                                       kw_args=None,\n",
       "                                                                                       pass_y='...\n",
       "                                                                                 handle_unknown='error',\n",
       "                                                                                 n_values=None,\n",
       "                                                                                 sparse=True))],\n",
       "                                                           verbose=False),\n",
       "                                                  ['Age Draft']),\n",
       "                                                 ('thresh',\n",
       "                                                  Pipeline(memory=None,\n",
       "                                                           steps=[('binarizer',\n",
       "                                                                   Binarizer(copy=True,\n",
       "                                                                             threshold=8))],\n",
       "                                                           verbose=False),\n",
       "                                                  ['GS'])],\n",
       "                                   verbose=False)),\n",
       "                ('regressor',\n",
       "                 Ridge(alpha=0.7, copy_X=True, fit_intercept=True,\n",
       "                       max_iter=None, normalize=True, random_state=None,\n",
       "                       solver='auto', tol=0.001))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 631,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pl_4.fit(pd.concat([fold_1_x, fold_3_x, fold_4_x, fold_5_x])[small_selection + small_sqrt + cat_feat + thresh_feat],\n",
    "         pd.concat([fold_1_y, fold_3_y, fold_4_y, fold_5_y]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 632,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/_function_transformer.py:97: FutureWarning: The default validate=True will be replaced by validate=False in 0.22.\n",
      "  \"validate=False in 0.22.\", FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/_function_transformer.py:97: FutureWarning: The default validate=True will be replaced by validate=False in 0.22.\n",
      "  \"validate=False in 0.22.\", FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/_function_transformer.py:97: FutureWarning: The default validate=True will be replaced by validate=False in 0.22.\n",
      "  \"validate=False in 0.22.\", FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/_function_transformer.py:97: FutureWarning: The default validate=True will be replaced by validate=False in 0.22.\n",
      "  \"validate=False in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('preprocessor',\n",
       "                 ColumnTransformer(n_jobs=None, remainder='drop',\n",
       "                                   sparse_threshold=0.3,\n",
       "                                   transformer_weights=None,\n",
       "                                   transformers=[('sqrt',\n",
       "                                                  Pipeline(memory=None,\n",
       "                                                           steps=[('sqrt',\n",
       "                                                                   FunctionTransformer(accept_sparse=False,\n",
       "                                                                                       check_inverse=True,\n",
       "                                                                                       func=<function <lambda> at 0x7f929026ca70>,\n",
       "                                                                                       inv_kw_args=None,\n",
       "                                                                                       inverse_func=None,\n",
       "                                                                                       kw_args=None,\n",
       "                                                                                       pass_y='...\n",
       "                                                                                 handle_unknown='error',\n",
       "                                                                                 n_values=None,\n",
       "                                                                                 sparse=True))],\n",
       "                                                           verbose=False),\n",
       "                                                  ['Age Draft']),\n",
       "                                                 ('thresh',\n",
       "                                                  Pipeline(memory=None,\n",
       "                                                           steps=[('binarizer',\n",
       "                                                                   Binarizer(copy=True,\n",
       "                                                                             threshold=8))],\n",
       "                                                           verbose=False),\n",
       "                                                  ['GS'])],\n",
       "                                   verbose=False)),\n",
       "                ('regressor',\n",
       "                 Ridge(alpha=0.7, copy_X=True, fit_intercept=True,\n",
       "                       max_iter=None, normalize=True, random_state=None,\n",
       "                       solver='auto', tol=0.001))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 632,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pl_5.fit(pd.concat([fold_2_x, fold_3_x, fold_4_x, fold_5_x])[small_selection + small_sqrt + cat_feat + thresh_feat],\n",
    "         pd.concat([fold_2_y, fold_3_y, fold_4_y, fold_5_y]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 633,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/_function_transformer.py:97: FutureWarning: The default validate=True will be replaced by validate=False in 0.22.\n",
      "  \"validate=False in 0.22.\", FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/_function_transformer.py:97: FutureWarning: The default validate=True will be replaced by validate=False in 0.22.\n",
      "  \"validate=False in 0.22.\", FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/_function_transformer.py:97: FutureWarning: The default validate=True will be replaced by validate=False in 0.22.\n",
      "  \"validate=False in 0.22.\", FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/_function_transformer.py:97: FutureWarning: The default validate=True will be replaced by validate=False in 0.22.\n",
      "  \"validate=False in 0.22.\", FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/_function_transformer.py:97: FutureWarning: The default validate=True will be replaced by validate=False in 0.22.\n",
      "  \"validate=False in 0.22.\", FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/_function_transformer.py:97: FutureWarning: The default validate=True will be replaced by validate=False in 0.22.\n",
      "  \"validate=False in 0.22.\", FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/_function_transformer.py:97: FutureWarning: The default validate=True will be replaced by validate=False in 0.22.\n",
      "  \"validate=False in 0.22.\", FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/_function_transformer.py:97: FutureWarning: The default validate=True will be replaced by validate=False in 0.22.\n",
      "  \"validate=False in 0.22.\", FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/_function_transformer.py:97: FutureWarning: The default validate=True will be replaced by validate=False in 0.22.\n",
      "  \"validate=False in 0.22.\", FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/_function_transformer.py:97: FutureWarning: The default validate=True will be replaced by validate=False in 0.22.\n",
      "  \"validate=False in 0.22.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "score_1 = pl_1.score(fold_5_x[small_selection + small_sqrt + cat_feat + thresh_feat], fold_5_y)\n",
    "score_2 = pl_2.score(fold_4_x[small_selection + small_sqrt + cat_feat + thresh_feat], fold_4_y)\n",
    "score_3 = pl_3.score(fold_3_x[small_selection + small_sqrt + cat_feat + thresh_feat], fold_3_y)\n",
    "score_4 = pl_4.score(fold_2_x[small_selection + small_sqrt + cat_feat + thresh_feat], fold_2_y)\n",
    "score_5 = pl_5.score(fold_1_x[small_selection + small_sqrt + cat_feat + thresh_feat], fold_1_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 634,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4697622510810015\n",
      "0.5187625482625597\n",
      "0.4576968079256763\n",
      "0.3428075787115199\n",
      "0.41442693504231337\n",
      "--------------------\n",
      "MEAN SCORE: 0.44069122420461415\n",
      "MEDIAN SCORE: 0.4576968079256763\n"
     ]
    }
   ],
   "source": [
    "print(score_1)\n",
    "print(score_2)\n",
    "print(score_3)\n",
    "print(score_4)\n",
    "print(score_5)\n",
    "print('--------------------')\n",
    "print('MEAN SCORE: ' + str(np.mean([score_1, score_2, score_3, score_4, score_5])))\n",
    "print('MEDIAN SCORE: ' + str(np.median([score_1, score_2, score_3, score_4, score_5])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 608,
   "metadata": {},
   "outputs": [],
   "source": [
    "coefs_mean = (pl_1.named_steps['regressor'].coef_ + pl_2.named_steps['regressor'].coef_ \n",
    "                + pl_3.named_steps['regressor'].coef_ + pl_4.named_steps['regressor'].coef_ \n",
    "                    + pl_5.named_steps['regressor'].coef_) / 5\n",
    "intercept_mean = (pl_1.named_steps['regressor'].intercept_ + pl_2.named_steps['regressor'].intercept_ \n",
    "                        + pl_3.named_steps['regressor'].intercept_ + pl_4.named_steps['regressor'].intercept_ \n",
    "                            + pl_5.named_steps['regressor'].intercept_) / 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 609,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 5.45817862e-02,  2.29819010e-01,  4.82258966e-02,  5.46704011e-01,\n",
       "       -2.94806195e-01, -7.46397055e-01,  2.94242502e-02, -5.23391507e-03,\n",
       "        6.68315980e-04,  1.64702345e+00,  4.34265138e-01, -2.99508097e-01,\n",
       "       -5.52203539e-01,  6.20203350e-01, -1.46645338e-01])"
      ]
     },
     "execution_count": 609,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coefs_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 610,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.2064671081672218"
      ]
     },
     "execution_count": 610,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intercept_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 611,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Coefficient</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Y/G</td>\n",
       "      <td>0.054582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Lng</td>\n",
       "      <td>0.229819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Projected Yds</td>\n",
       "      <td>0.048226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Yds</td>\n",
       "      <td>0.546704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1D</td>\n",
       "      <td>-0.294806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>EYds</td>\n",
       "      <td>-0.746397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>Rec Pts/G First Season</td>\n",
       "      <td>0.029424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>WR Tgt Share</td>\n",
       "      <td>-0.005234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>WR Rec Share</td>\n",
       "      <td>0.000668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>20</td>\n",
       "      <td>1.647023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>21</td>\n",
       "      <td>0.434265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>22</td>\n",
       "      <td>-0.299508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>23</td>\n",
       "      <td>-0.552204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>24</td>\n",
       "      <td>0.620203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>GS</td>\n",
       "      <td>-0.146645</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Feature  Coefficient\n",
       "0                      Y/G     0.054582\n",
       "1                      Lng     0.229819\n",
       "2            Projected Yds     0.048226\n",
       "3                      Yds     0.546704\n",
       "4                       1D    -0.294806\n",
       "5                     EYds    -0.746397\n",
       "6   Rec Pts/G First Season     0.029424\n",
       "7             WR Tgt Share    -0.005234\n",
       "8             WR Rec Share     0.000668\n",
       "9                       20     1.647023\n",
       "10                      21     0.434265\n",
       "11                      22    -0.299508\n",
       "12                      23    -0.552204\n",
       "13                      24     0.620203\n",
       "14                      GS    -0.146645"
      ]
     },
     "execution_count": 611,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_coeff = pd.DataFrame(zip(small_selection + small_sqrt + \n",
    "                            list(set(X_full_train['Age Draft'].unique())) + thresh_feat, coefs_mean))\n",
    "df_coeff.columns = ['Feature', 'Coefficient']\n",
    "df_coeff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 612,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl_final = Pipeline(steps=[('preprocessor', preproc1), ('regressor', Ridge(alpha = .7, normalize = True))])\n",
    "pl_final.named_steps['regressor'].coef_ = coefs_mean\n",
    "pl_final.named_steps['regressor'].intercept_ = intercept_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 613,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/_function_transformer.py:97: FutureWarning: The default validate=True will be replaced by validate=False in 0.22.\n",
      "  \"validate=False in 0.22.\", FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/_function_transformer.py:97: FutureWarning: The default validate=True will be replaced by validate=False in 0.22.\n",
      "  \"validate=False in 0.22.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "y_train_pred = pl_final.predict(X_full_train[small_selection + small_sqrt + cat_feat + thresh_feat])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 614,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(y_train_pred, y_train_pred - y_full_train, c = 'b', label = 'Training')\n",
    "plt.plot(range(14), [0] * 14, color = 'r', label = 'Correct Prediction')\n",
    "plt.xlabel('Prediction')\n",
    "plt.ylabel('Residual')\n",
    "plt.legend(loc='upper left')\n",
    "plt.show()\n",
    "#Save this FIGURE and then "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
